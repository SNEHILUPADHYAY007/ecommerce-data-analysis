{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac4963b-e955-4e73-81f8-d25c014ef9ca",
   "metadata": {},
   "source": [
    "# Installing required packages\n",
    "`pyodbc polars import-ipynb`\n",
    "**REMOVED SERVER NAME AND DB NAME**"
    
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb69526e-5e23-4c69-a3c1-f2fc7d47897d",
   "metadata": {},
   "source": [
    "# Importing Libraries, Classes from User-defines module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a8955a4-c3e1-415e-aa1b-00aa383c9ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from database.ipynb\n",
      "importing Jupyter notebook from data_prepn.ipynb\n",
      "Connected to SQL Server successfully.\n",
      "Query Executed Successfully:-IF NOT EXISTS (SELECT * from sys.databases where name = 'ecommerce_raw_dataset')\n",
      "            BEGIN \n",
      "                EXEC('CREATE DATABASE ecommerce_raw_dataset');\n",
      "            END\n",
      "            \n",
      "Query Executed Successfully:-IF NOT EXISTS (SELECT * from sys.databases where name = 'ecommerce_in_dataset')\n",
      "            BEGIN \n",
      "                EXEC('CREATE DATABASE ecommerce_in_dataset');\n",
      "            END\n",
      "            \n",
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from database import SQLServerDB\n",
    "from data_prepn import PrepareData\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "\n",
    "# Checking and creating required DB in SQL Server\n",
    "databases = [\"ecommerce_raw_dataset\", \"ecommerce_in_dataset\"]\n",
    "obj = SQLServerDB()\n",
    "obj.connect()\n",
    "for db in databases:\n",
    "    sql = f\"\"\"IF NOT EXISTS (SELECT * from sys.databases where name = '{db}')\n",
    "            BEGIN \n",
    "                EXEC('CREATE DATABASE {db}');\n",
    "            END\n",
    "            \"\"\"\n",
    "    obj.execute_queries(sql)\n",
    "obj.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1d521-5678-44f2-a2ae-67efb4dd6056",
   "metadata": {},
   "source": [
    "# Read the required CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c0f1ba-646b-4277-84a9-d8c3e261ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static File Paths\n",
    "# file_paths = ['data/data/data/aisles.csv', 'data/data/data/departments.csv', 'data/data/data/order_products.csv', 'data/data/data/orders.csv', 'data/data/data/products.csv']\n",
    "file_paths = ['data/data/data/aisles.csv', 'data/data/data/departments.csv']\n",
    "# Reading the required CSV files\n",
    "data_obj = PrepareData(file_paths)\n",
    "dataframes = data_obj.read_file()\n",
    "# print(dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66c1afa-15e3-4566-b43d-a8bc54f4a6d2",
   "metadata": {},
   "source": [
    "# Perform Transformation for RAW TABLES\n",
    "**All cols must be of type STRING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce989f3-b8cc-4dd8-bce1-02dd31aeb182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Class method to change col type from int to str\n",
    "raw_dfs = data_obj.int_to_str(dataframes)\n",
    "# print(raw_dfs['aisles'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b8007-9422-4535-ac48-491362e00cc9",
   "metadata": {},
   "source": [
    "# Creating tables in RAW Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dbf2f2-8672-49ca-8de3-11b1ecf77679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the SQL queries to create the table in RAW DATASET\n",
    "sql_queries = []\n",
    "for key, df in raw_dfs.items():\n",
    "    col_name = data_obj.get_col_name(df)\n",
    "    values = ','.join([f\"{str} varchar(1000)\" for str in col_name])\n",
    "    sql = f\"\"\"\n",
    "            IF NOT EXISTS (SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = '{key}')\n",
    "            BEGIN\n",
    "                CREATE TABLE {key} ({values});\n",
    "            END;\n",
    "        \"\"\"\n",
    "    sql_queries.append(sql)\n",
    "\n",
    "# print(sql_queries)\n",
    "\n",
    "# Running the queries in Already made DB\n",
    "obj_raw_table = SQLServerDB()\n",
    "obj_raw_table.connect()\n",
    "\n",
    "try:\n",
    "    for query in sql_queries:\n",
    "        obj_raw_table.execute_queries(query)\n",
    "except Exception as e:\n",
    "    print(f\"Exception occured:{e}\")\n",
    "finally:\n",
    "    print(\"All raw tables created\")\n",
    "\n",
    "# Close the connection\n",
    "obj_raw_table.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e9c39f-08fb-4af5-ab09-2347692b5aab",
   "metadata": {},
   "source": [
    "# Insert data into RAW Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b9586-f240-4047-a676-0ec31b7f62be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in raw_dfs.items():\n",
    "    # Convert Polars DataFrame to Pandas DataFrame\n",
    "    pandas_df = df.to_pandas()\n",
    "    \n",
    "    # Get column names dynamically\n",
    "    columns = pandas_df.columns\n",
    "    column_names = ', '.join(columns)\n",
    "    placeholders = ', '.join(['?'] * len(columns))\n",
    "    insert_query = f\"INSERT INTO {key} ({column_names}) VALUES ({placeholders})\"\n",
    "    \n",
    "    # Convert DataFrame to list of tuples\n",
    "    data = pandas_df.values.tolist()\n",
    "\n",
    "    insert_data_into_raw = SQLServerDB()\n",
    "    insert_data_into_raw.connect()\n",
    "    insert_data_into_raw.insert_data(insert_query, data)    \n",
    "    insert_data_into_raw.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e2b28-f208-4a0c-a2bb-ad06f5d39882",
   "metadata": {},
   "source": [
    "# Create the Insight tables and do the analysis on following questions:-\n",
    "## Steps:-\n",
    "**Create table > Perform transformation > Check for Null Values(only for INT cols) > Fill Nulls(default 0) > Insert the data into the respective tables > perform below analysis**\n",
    "\n",
    "1. Create a temporary table that joins the orders, order_products, and products tables to get information about each order, including the products that were purchased and their department and aisle information.\n",
    "2. Create a temporary table that groups the orders by product and finds the total number of times each product was purchased, the total number of times each product was reordered, and the average number of times each product was added to a cart.\n",
    "3. Create a temporary table that groups the orders by department and finds the total number of products purchased, the total number of unique products purchased, the total number of products purchased on weekdays vs weekends, and the average time of day that products in each department are ordered.\n",
    "4. Create a temporary table that groups the orders by aisle and finds the top 10 most popular aisles, including the total number of products purchased and the total number of unique products purchased from each aisle.\n",
    "5. Combine the information from the previous temporary tables into a final table that shows the product ID, product name, department ID, department name, aisle ID, aisle name, total number of times purchased, total number of times reordered, average number of times added to cart, total number of products purchased, total number of unique products purchased, total number of products purchased on weekdays, total number of products purchased on weekends, and average time of day products are ordered in each department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aeb4f62-eb12-48b9-8178-9a885730a8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to SQL Server successfully.\n",
      "Error while executing the query:- ('42S01', \"[42S01] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]There is already an object named 'aisles' in the database. (2714) (SQLExecDirectW)\")\n",
      "Error while executing the query:- ('42S01', \"[42S01] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]There is already an object named 'departments' in the database. (2714) (SQLExecDirectW)\")\n",
      "Error while executing the query:- ('42S01', \"[42S01] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]There is already an object named 'orders' in the database. (2714) (SQLExecDirectW)\")\n",
      "Query Executed Successfully:-CREATE TABLE order_products (\n",
      "        order_id INTEGER,\n",
      "        product_id INTEGER,\n",
      "        add_to_cart_order INTEGER,\n",
      "        reordered INTEGER,\n",
      "        PRIMARY KEY (order_id, product_id),\n",
      "        FOREIGN KEY (order_id) REFERENCES orders (order_id),\n",
      "        FOREIGN KEY (product_id) REFERENCES products (product_id)\n",
      "    )\n",
      "Error while executing the query:- ('42S01', \"[42S01] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]There is already an object named 'products' in the database. (2714) (SQLExecDirectW)\")\n",
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Creating the Insight table in Insight dataset\n",
    "ddl_sql_path = 'insight_tbl_ddl_queries'\n",
    "insight_obj = SQLServerDB()\n",
    "insight_obj.connect()\n",
    "\n",
    "for file_name in os.listdir(ddl_sql_path):\n",
    "    com_file_path = f\"{ddl_sql_path}/{file_name}\"\n",
    "    \n",
    "    if os.path.isfile(com_file_path):\n",
    "        with open(com_file_path, 'r') as f:\n",
    "            sql = f.read()\n",
    "            insight_obj.execute_queries(sql)\n",
    "            \n",
    "insight_obj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440becb0-6ae0-4f4a-87e3-36f6d8ae90d4",
   "metadata": {},
   "source": [
    "# Transforming the data as per the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57c84a1d-3726-45a7-b927-048254ad9e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to SQL Server successfully.\n",
      "shape: (32_434_489, 4)\n",
      "┌──────────┬────────────┬───────────────────┬───────────┐\n",
      "│ order_id ┆ product_id ┆ add_to_cart_order ┆ reordered │\n",
      "│ ---      ┆ ---        ┆ ---               ┆ ---       │\n",
      "│ i64      ┆ i64        ┆ i64               ┆ i64       │\n",
      "╞══════════╪════════════╪═══════════════════╪═══════════╡\n",
      "│ 28       ┆ 27548      ┆ 9                 ┆ 1         │\n",
      "│ 93       ┆ 39408      ┆ 11                ┆ 0         │\n",
      "│ 146      ┆ 26348      ┆ 6                 ┆ 1         │\n",
      "│ 213      ┆ 26165      ┆ 11                ┆ 1         │\n",
      "│ 265      ┆ 41658      ┆ 4                 ┆ 1         │\n",
      "│ …        ┆ …          ┆ …                 ┆ …         │\n",
      "│ 3421083  ┆ 39678      ┆ 6                 ┆ 1         │\n",
      "│ 3421083  ┆ 11352      ┆ 7                 ┆ 0         │\n",
      "│ 3421083  ┆ 4600       ┆ 8                 ┆ 0         │\n",
      "│ 3421083  ┆ 24852      ┆ 9                 ┆ 1         │\n",
      "│ 3421083  ┆ 5020       ┆ 10                ┆ 1         │\n",
      "└──────────┴────────────┴───────────────────┴───────────┘\n",
      "Connected to SQL Server successfully.\n",
      "Data Inserted\n",
      "Connection closed.\n",
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "raw_obj = SQLServerDB()\n",
    "insight = PrepareData(None)\n",
    "raw_obj.connect()\n",
    "\n",
    "str_to_int_dict = {\n",
    "    'aisles': ['aisle_id'],\n",
    "    'departments':['department_id'],\n",
    "    'order_products':['order_id', 'product_id', 'add_to_cart_order', 'reordered'],\n",
    "    'orders':['order_id', 'user_id', 'order_number', 'order_dow', 'order_hour_of_day'],\n",
    "    'products':['product_id', 'aisle_id', 'department_id']\n",
    "}\n",
    "\n",
    "sql = \"SELECT * FROM INFORMATION_SCHEMA.TABLES\"\n",
    "df = raw_obj.read_the_table(sql)\n",
    "table_names = df.select(pl.col(\"TABLE_NAME\"))\n",
    "tbl_name_list = table_names[\"TABLE_NAME\"].to_list()\n",
    "\n",
    "for tbl_name in tbl_name_list:\n",
    "    sql = f\"SELECT * FROM {tbl_name}\"\n",
    "    get_data = raw_obj.read_the_table(sql)\n",
    "    if tbl_name == 'orders':\n",
    "        get_data = insight.fill_nulls(get_data,'days_since_prior_order').select(\"*\").with_columns(pl.col('days_since_prior_order').cast(pl.Float64).cast(pl.Int64))\n",
    "        get_data = insight.str_to_int(get_data, str_to_int_dict.get(tbl_name))\n",
    "        final_in_df = get_data.drop(pl.col(\"eval_set\"))\n",
    "    else:\n",
    "        final_in_df =  insight.str_to_int(get_data, str_to_int_dict.get(tbl_name))\n",
    "    print(final_in_df)\n",
    "    # Convert Polars DataFrame to Pandas DataFrame\n",
    "    pandas_df = final_in_df.to_pandas()\n",
    "    \n",
    "    # Get column names dynamically\n",
    "    columns = pandas_df.columns\n",
    "    column_names = ', '.join(columns)\n",
    "    placeholders = ', '.join(['?'] * len(columns))\n",
    "    insert_query = f\"INSERT INTO {tbl_name} ({column_names}) VALUES ({placeholders})\"\n",
    "    \n",
    "    # Convert DataFrame to list of tuples\n",
    "    data = pandas_df.values.tolist()\n",
    "    \n",
    "    insert_data_into_raw = SQLServerDB()\n",
    "    insert_data_into_raw.connect()\n",
    "    insert_data_into_raw.insert_data(insert_query, data)    \n",
    "    insert_data_into_raw.close()\n",
    "    # print(get_data)\n",
    "raw_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65194688-3947-4661-a665-bca748c44193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
